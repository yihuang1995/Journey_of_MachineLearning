{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "lasting-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# define a floating point model\n",
    "class M(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# create a model instance\n",
    "model_fp32 = M()\n",
    "# create a quantized model instance\n",
    "model_int8 = torch.quantization.quantize_dynamic(\n",
    "    model_fp32,  # the original model\n",
    "    {torch.nn.Linear},  # a set of layers to dynamically quantize\n",
    "    dtype=torch.qint8)  # the target dtype for quantized weights\n",
    "\n",
    "# run the model\n",
    "input_fp32 = torch.randn(4, 4, 4, 4)\n",
    "res = model_int8(input_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "invisible-norway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.0240e+00,  1.5521e-01,  7.5095e-02,  4.4543e-01],\n",
       "          [ 4.3773e-01,  1.7560e+00, -5.5713e-01,  8.9000e-01],\n",
       "          [-5.7184e-01,  1.9503e+00, -7.9842e-01,  4.2823e-01],\n",
       "          [ 6.4926e-02, -5.2784e-01, -6.2297e-01, -8.8784e-01]],\n",
       "\n",
       "         [[ 1.3309e+00,  6.3560e-01, -5.2023e-01, -3.9306e-01],\n",
       "          [ 1.3031e+00,  1.4272e+00, -1.0994e+00, -1.0564e-01],\n",
       "          [ 2.7697e-01, -1.3815e-01,  1.0761e+00, -3.3645e-01],\n",
       "          [-5.0866e-01, -1.0265e-01,  1.2904e-01, -5.5304e-01]],\n",
       "\n",
       "         [[-3.5448e-01,  5.7023e-01,  4.4133e-01,  5.2111e-01],\n",
       "          [-2.4876e-01,  1.4459e+00, -1.1869e+00,  6.8687e-01],\n",
       "          [ 5.9504e-01,  3.0127e-01, -5.6746e-01,  3.2533e-01],\n",
       "          [ 8.8590e-01,  4.5952e-01,  1.3219e+00,  2.9233e-01]],\n",
       "\n",
       "         [[ 4.9684e-01,  6.4014e-01, -5.7715e-01, -5.8228e-01],\n",
       "          [ 5.8816e-01,  1.4389e+00, -1.0417e+00,  1.1222e+00],\n",
       "          [ 1.7804e+00, -1.3831e-01,  4.3836e-01, -3.4255e-01],\n",
       "          [ 3.9738e-01,  8.6235e-01, -2.0200e-01,  5.8304e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0044e+00, -7.7617e-01,  1.4640e+00, -5.5616e-01],\n",
       "          [ 3.1982e-01,  3.2816e-01,  2.7213e-01, -5.7978e-01],\n",
       "          [ 1.1746e+00,  2.4122e-01,  2.7260e-01, -1.0689e-01],\n",
       "          [ 2.0817e-01,  8.7016e-01, -1.7276e-01,  6.8484e-01]],\n",
       "\n",
       "         [[ 3.6705e-01,  4.0323e-01, -1.3013e+00,  1.4268e-01],\n",
       "          [ 4.3033e-02,  1.8058e+00, -1.8558e-01,  9.6397e-01],\n",
       "          [ 1.3453e+00, -4.7123e-01,  6.3727e-01, -5.9807e-01],\n",
       "          [ 2.9730e-01,  5.4928e-01, -8.7786e-01, -2.0338e-01]],\n",
       "\n",
       "         [[ 5.3875e-01,  5.7321e-02, -1.3711e-01, -3.3098e-01],\n",
       "          [ 3.4140e-01,  1.5302e-01, -1.5181e-01, -1.1925e-01],\n",
       "          [-6.8599e-01,  1.9337e-01,  7.6018e-01, -1.2066e-01],\n",
       "          [ 8.9779e-01, -3.1689e-01, -5.2946e-01, -7.0879e-01]],\n",
       "\n",
       "         [[ 1.3378e+00, -9.1894e-01,  8.8763e-01, -7.9995e-01],\n",
       "          [ 5.1404e-01,  8.9112e-01,  4.8324e-01,  5.3753e-01],\n",
       "          [-4.8020e-01,  1.1527e+00,  6.5728e-01,  8.4980e-02],\n",
       "          [ 1.0235e+00, -9.3317e-01,  1.5726e+00, -2.7938e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.7799e-01,  5.3224e-01,  4.6729e-01, -4.4031e-02],\n",
       "          [ 8.2491e-01,  1.0727e+00, -1.6135e-01,  4.0305e-01],\n",
       "          [ 5.1967e-01,  1.0386e+00, -8.6817e-01, -3.3254e-01],\n",
       "          [ 7.0763e-01,  2.4873e-01, -5.6355e-01, -2.8549e-02]],\n",
       "\n",
       "         [[ 5.0872e-01,  3.9197e-01, -7.2758e-01, -3.6413e-01],\n",
       "          [ 1.1424e+00,  6.5593e-01, -8.9256e-02,  3.7725e-01],\n",
       "          [ 1.2529e-01,  2.7203e-01, -2.2546e-01,  2.1477e-01],\n",
       "          [ 5.3750e-01, -1.7041e+00,  1.8461e+00, -7.7837e-01]],\n",
       "\n",
       "         [[ 5.1404e-01,  9.2568e-01,  2.0364e-01,  3.0829e-01],\n",
       "          [ 9.0185e-01,  5.2973e-01,  1.5344e-01,  4.4136e-01],\n",
       "          [-9.1430e-01,  1.0533e+00, -1.3320e-01,  5.1533e-01],\n",
       "          [ 6.9200e-01,  3.6945e-01,  7.4235e-01, -2.9331e-02]],\n",
       "\n",
       "         [[ 9.2249e-01,  4.2152e-02,  1.5283e+00, -1.2456e-01],\n",
       "          [ 9.1780e-01, -2.6544e-01, -5.5338e-01, -1.3426e-01],\n",
       "          [ 3.8049e-01, -4.3980e-01,  6.2851e-01, -3.0815e-01],\n",
       "          [ 8.2554e-01,  7.7102e-01,  5.3250e-01,  7.3941e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 6.6666e-01,  2.0733e+00, -9.1586e-01,  1.2614e+00],\n",
       "          [-1.3384e+00,  8.4718e-01,  9.1984e-02,  2.5746e-01],\n",
       "          [-3.3665e-01,  1.0896e+00, -7.7825e-01,  9.5037e-01],\n",
       "          [-6.5096e-01,  9.5320e-02,  2.4648e-01, -5.4553e-01]],\n",
       "\n",
       "         [[ 1.1868e+00, -4.2072e-01,  2.8292e-01, -6.8269e-02],\n",
       "          [ 3.6673e-01, -9.0533e-01,  1.3289e+00,  5.8239e-02],\n",
       "          [ 8.2304e-01,  5.3599e-01, -7.5495e-02,  4.3401e-01],\n",
       "          [ 1.4432e+00,  3.4380e-01, -6.3454e-02, -2.0338e-01]],\n",
       "\n",
       "         [[ 4.0927e-01,  8.1277e-01, -5.6902e-01, -1.9290e-01],\n",
       "          [ 3.6153e-02,  1.8372e+00, -1.3534e+00,  4.0039e-01],\n",
       "          [ 1.2797e+00, -5.9743e-01,  7.4970e-01,  5.0733e-02],\n",
       "          [ 8.2617e-01, -5.0735e-02,  3.9879e-01, -8.1246e-01]],\n",
       "\n",
       "         [[ 4.0927e-01, -6.8562e-02,  2.8292e-01,  1.6723e-01],\n",
       "          [ 1.4373e-03,  1.6725e-01,  4.5540e-02,  2.2853e-01],\n",
       "          [ 1.2468e+00,  6.8611e-01, -8.6582e-01, -4.9377e-01],\n",
       "          [ 4.0020e-01, -8.8891e-01,  1.8628e-01, -7.5023e-01]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "communist-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fp32.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "received-sense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "jewish-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f11449f7c10>\n"
     ]
    }
   ],
   "source": [
    "print(model_fp32.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pacific-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4070, -0.3779,  0.1892,  0.3390],\n",
      "        [-0.4217, -0.0338,  0.3939,  0.2279],\n",
      "        [-0.2858, -0.4249, -0.4494, -0.0818],\n",
      "        [-0.2770,  0.0165, -0.2295,  0.2479]], requires_grad=True)\n",
      "torch.float32\n",
      "Parameter containing:\n",
      "tensor([-0.0713, -0.3136,  0.0278, -0.3181], requires_grad=True)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for param in model_fp32.parameters():\n",
    "    print(param)\n",
    "    print(param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "artistic-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_int8.parameters():\n",
    "    print(param)\n",
    "    print(param.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-harmony",
   "metadata": {},
   "source": [
    "References:\n",
    "* https://huggingface.co/docs/optimum/concept_guides/quantization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
