{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nutritional-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statistics import mode \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from dtree import *\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1., 0.], [2., 1.], [0., 0.]])\n",
    "y = np.array([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse = coo_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_sparse, y = resample(X, X_sparse, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_index = [2, 0, 1, 4, 2, 5, 6, 0, 4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in a if x not in set(bag_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-johnson",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "immune-longer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "class DecisionNode:\n",
    "    def __init__(self, col, split, lchild, rchild):\n",
    "        self.col = col\n",
    "        self.split = split\n",
    "        self.lchild = lchild\n",
    "        self.rchild = rchild\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        # Make decision based upon x_test[col] and split\n",
    "        if x_test[self.col] > self.split:\n",
    "            return self.rchild\n",
    "        return self.lchild\n",
    "\n",
    "    def leaf(self, x_test):\n",
    "        # pass in a single x observation\n",
    "        branch = self.predict(x_test)\n",
    "        if isinstance(branch, LeafNode):\n",
    "            return branch\n",
    "        return branch.leaf(x_test)\n",
    "\n",
    "\n",
    "class LeafNode:\n",
    "    def __init__(self, y, prediction):\n",
    "        \"Create leaf node from y values and prediction; prediction is mean(y) or mode(y)\"\n",
    "        self.n = len(y)\n",
    "        self.prediction = prediction\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        # return prediction\n",
    "        return self.prediction\n",
    "\n",
    "def gini(y):\n",
    "    \"Return the gini impurity score for values in y\"\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    p = counts / len(y)\n",
    "    return 1 - np.sum( p**2 )\n",
    "\n",
    "\n",
    "class DecisionTree621():\n",
    "    def __init__(self, min_samples_leaf=1, loss=None, max_features=1):\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.loss = loss # loss function; either np.std or gini\n",
    "        self.max_features = max_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Create a decision tree fit to (X,y) and save as self.root, the root of\n",
    "        our decision tree, for either a classifier or regressor.  Leaf nodes for classifiers\n",
    "        predict the most common class (the mode) and regressors predict the average y\n",
    "        for samples in that leaf.  \n",
    "              \n",
    "        This function is a wrapper around fit_() that just stores the tree in self.root.\n",
    "        \"\"\"\n",
    "        self.root = self.fit_(X, y)\n",
    "\n",
    "\n",
    "    def fit_(self, X, y):\n",
    "        \"\"\"\n",
    "        Recursively create and return a decision tree fit to (X,y) for\n",
    "        either a classifier or regressor.  This function should call self.create_leaf(X,y)\n",
    "        to create the appropriate leaf node, which will invoke either\n",
    "        RegressionTree621.create_leaf() or ClassifierTree621. create_leaf() depending\n",
    "        on the type of self.\n",
    "        \n",
    "        This function is not part of the class \"interface\" and is for internal use, but it\n",
    "        embodies the decision tree fitting algorithm.\n",
    "\n",
    "        (Make sure to call fit_() not fit() recursively.)\n",
    "        \"\"\"\n",
    "        if len(y) <= self.min_samples_leaf:\n",
    "            return self.create_leaf(y)\n",
    "        \n",
    "        col, split = self.find_best_split(X, y, self.loss, self.max_features, self.min_samples_leaf)\n",
    "\n",
    "        if col == -1:\n",
    "            return self.create_leaf(y)\n",
    "\n",
    "        lchild = self.fit_(X[X[:,col]<=split],y[X[:,col]<=split])\n",
    "        rchild = self.fit_(X[X[:,col]>split],y[X[:,col]>split])\n",
    "\n",
    "        return DecisionNode(col, split, lchild, rchild)\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Make a prediction for each record in X_test and return as array.\n",
    "        This method is inherited by RegressionTree621 and ClassifierTree621 and\n",
    "        works for both without modification!\n",
    "        \"\"\"\n",
    "        X_pred = np.zeros(len(X_test))\n",
    "        for i, val in enumerate(X_test):\n",
    "            pred = self.dfs(self.root, val)\n",
    "            X_pred[i] = pred\n",
    "        return X_pred\n",
    "\n",
    "\n",
    "    def dfs(self, tree, x):\n",
    "        # pass in a single x observation\n",
    "        if isinstance(tree, LeafNode):\n",
    "            return tree.prediction\n",
    "        branch = tree.predict(x)\n",
    "        return self.dfs(branch, x)\n",
    "\n",
    "\n",
    "    def find_best_split(self, X, y, loss, max_features, min_samples_leaf):\n",
    "        best = (-1, -1, loss(y))\n",
    "        ncol = len(X[0,:])\n",
    "        selected_feature = int(max_features*ncol)\n",
    "        vars = [random.choice(range(ncol)) for i in range(selected_feature)]\n",
    "        for col in vars:\n",
    "            candidates = [random.choice(X[:,col]) for i in range(11)]\n",
    "            for split in candidates:\n",
    "                yl = y[X[:,col]<=split]\n",
    "                yr = y[X[:,col]>split]\n",
    "                if len(yl) < min_samples_leaf or len(yr) < min_samples_leaf:\n",
    "                    continue\n",
    "                l = (len(yl)*loss(yl) + len(yr)*loss(yr))/len(y)\n",
    "                if l == 0:\n",
    "                    return (col, split)\n",
    "                if l < best[2]:\n",
    "                    best = (col, split, l)\n",
    "        return (best[0], best[1])\n",
    "\n",
    "\n",
    "\n",
    "class RegressionTree621(DecisionTree621):\n",
    "    def __init__(self, min_samples_leaf=1, max_features=1):\n",
    "        super().__init__(min_samples_leaf, loss=np.std, max_features=max_features)\n",
    "    def score(self, X_test, y_test):\n",
    "        \"Return the R^2 of y_test vs predictions for each record in X_test\"\n",
    "        return r2_score(y_test, self.predict(X_test))\n",
    "    def create_leaf(self, y):\n",
    "        \"\"\"\n",
    "        Return a new LeafNode for regression, passing y and mean(y) to\n",
    "        the LeafNode constructor.\n",
    "        \"\"\"\n",
    "        return LeafNode(y, prediction=np.mean(y))\n",
    "\n",
    "\n",
    "class ClassifierTree621(DecisionTree621):\n",
    "    def __init__(self, min_samples_leaf=1, max_features=1):\n",
    "        super().__init__(min_samples_leaf, loss=gini, max_features=max_features)\n",
    "    def score(self, X_test, y_test):\n",
    "        \"Return the accuracy_score() of y_test vs predictions for each record in X_test\"\n",
    "        return accuracy_score(y_test, self.predict(X_test))\n",
    "    def create_leaf(self, y):\n",
    "        \"\"\"\n",
    "        Return a new LeafNode for classification, passing y and mode(y) to\n",
    "        the LeafNode constructor.\n",
    "        \"\"\"\n",
    "        return LeafNode(y, prediction=mode(y))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from test_rf import *\n",
    "    X, y = load_boston(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "    dt = RegressionTree621(min_samples_leaf=1, max_features=10)\n",
    "    dt.fit(X,y)\n",
    "    print(dt.max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-canyon",
   "metadata": {},
   "source": [
    "# Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "arctic-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statistics import mode \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from dtree import *\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class RandomForest621:\n",
    "    def __init__(self, n_estimators=10, oob_score=False):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.oob_score = oob_score\n",
    "        self.oob_score_ = np.nan\n",
    "        self.trees = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Given an (X, y) training set, fit all n_estimators trees to different,\n",
    "        bootstrapped versions of the training data.  Keep track of the indexes of\n",
    "        the OOB records for each tree.  After fitting all of the trees in the forest,\n",
    "        compute the OOB validation score estimate and store as self.oob_score_, to\n",
    "        mimic sklearn.\n",
    "        \"\"\"\n",
    "        self.forest = []\n",
    "        self.oob_index = []\n",
    "        for i in range(self.n_estimators):\n",
    "            tree = self.trees(self.min_samples_leaf,self.max_features)\n",
    "            bag_idx = resample(range(len(X)))\n",
    "            oob_idx = [x for x in range(len(X)) if x not in set(bag_idx)]\n",
    "            bag_X = X[bag_idx]\n",
    "            bag_y = y[bag_idx]\n",
    "            tree.fit(bag_X,bag_y)\n",
    "            self.forest.append(tree)\n",
    "            self.oob_index.append(oob_idx)\n",
    "\n",
    "\n",
    "        if self.oob_score:\n",
    "            self.oob_score_ = None #... compute OOB score ...\n",
    "\n",
    "class RandomForestRegressor621(RandomForest621):\n",
    "    def __init__(self, n_estimators=10, min_samples_leaf=3, max_features=0.3, oob_score=False):\n",
    "        super().__init__(n_estimators, oob_score=oob_score)\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.trees = RegressionTree621\n",
    "\n",
    "    def predict(self, X_test) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a 2D nxp array with one or more records, compute the weighted average\n",
    "        prediction from all trees in this forest. Weight each trees prediction by\n",
    "        the number of samples in the leaf making that prediction.  Return a 1D vector\n",
    "        with the predictions for each input record of X_test.\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for row in X_test:\n",
    "            leaves = [tree_.root.leaf(row) for tree_ in self.forest]\n",
    "            nobs = sum([leaf.n for leaf in leaves])\n",
    "            y_sum = sum([leaf.n *leaf.prediction for leaf in leaves]) #np.sum(leaf.y)\n",
    "            result.append(y_sum/nobs) \n",
    "        return np.array(result)\n",
    "        \n",
    "    def score(self, X_test, y_test) -> float:\n",
    "        \"\"\"\n",
    "        Given a 2D nxp X_test array and 1D nx1 y_test array with one or more records,\n",
    "        collect the prediction for each record and then compute R^2 on that and y_test.\n",
    "        \"\"\"\n",
    "        return r2_score(y_test, self.predict(X_test))\n",
    "class RandomForestClassifier621:\n",
    "    def __init__(self, n_estimators=10, min_samples_leaf=3, max_features=0.3, oob_score=False):\n",
    "        super().__init__(n_estimators, oob_score=oob_score)\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.trees = ClassifierTree621\n",
    "\n",
    "    def predict(self, X_test) -> np.ndarray:\n",
    "        result = []\n",
    "        for row in X_test:\n",
    "            counter = Counter()\n",
    "            for sub_tree in self.forest:\n",
    "                counter += Counter(sub_tree.root.leaf(row).y)\n",
    "            result.append(counter.most_common(1)[0][0])\n",
    "        return np.array(result)        \n",
    "        \n",
    "    def score(self, X_test, y_test) -> float:\n",
    "        \"\"\"\n",
    "        Given a 2D nxp X_test array and 1D nx1 y_test array with one or more records,\n",
    "        collect the predicted class for each record and then compute accuracy between\n",
    "        that and y_test.\n",
    "        \"\"\"\n",
    "        return accuracy_score(y_test, self.predict(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "universal-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import \\\n",
    "    load_boston, load_iris, load_diabetes, load_wine, \\\n",
    "    load_breast_cancer, fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aboriginal-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dietary-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "other-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier621(min_samples_leaf=5, max_features=0.6, oob_score=False, n_estimators=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ranging-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.trees.max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "quick-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adverse-subdivision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.37142857, 17.4875    , 18.35714286, 10.08333333, 21.08888889,\n",
       "       23.94      , 13.82857143, 13.71428571, 27.52857143, 27.64      ,\n",
       "       18.35714286, 13.8       , 22.44      , 27.52857143, 23.66      ,\n",
       "       45.74      , 19.2       ,  8.43333333, 24.42      , 23.66      ,\n",
       "       17.33333333, 24.86      , 45.74      , 17.4875    , 10.08333333,\n",
       "       24.42      , 27.64      , 45.74      , 36.8       , 14.38      ,\n",
       "       17.33333333, 18.54      , 22.73333333, 25.3625    , 13.675     ,\n",
       "       22.73333333, 22.28333333, 28.38      , 13.675     , 27.64      ,\n",
       "       22.44      , 28.37142857, 21.24285714, 18.35714286, 17.03333333,\n",
       "       19.2       , 19.7       , 14.4       , 14.38      , 13.675     ,\n",
       "       20.9       , 11.55      , 24.42      , 22.28333333, 21.11666667,\n",
       "       27.775     , 22.28333333, 27.64      , 20.92      ,  8.43333333,\n",
       "       36.8       , 23.04      , 28.37142857, 23.94      , 14.4       ,\n",
       "       20.9       , 34.54      , 19.2       , 27.52857143, 23.72857143,\n",
       "       28.38      , 23.66      , 28.38      , 18.6       ,  8.64      ,\n",
       "       25.3625    , 22.44      , 27.52857143, 20.9       ,  8.43333333,\n",
       "       13.82857143, 20.92      , 21.08888889, 19.7       , 34.54      ,\n",
       "       13.71428571, 23.66      , 13.82857143, 27.91428571, 45.74      ,\n",
       "       50.        , 35.28      , 14.82      , 25.48      , 13.82857143,\n",
       "       21.24285714, 18.35714286, 21.03333333, 12.425     , 23.04      ,\n",
       "       22.28333333, 13.71428571, 19.7       , 18.54      , 23.04      ,\n",
       "       14.82      , 13.71428571,  8.43333333, 24.86      , 17.33333333,\n",
       "       42.5       , 21.24285714, 17.33333333, 14.42      , 28.37142857,\n",
       "       27.91428571, 35.6       , 14.26      , 13.82857143, 20.68571429,\n",
       "       34.54      , 19.7       , 35.6       ,  8.64      , 19.51428571,\n",
       "       45.74      , 28.38      , 24.42      , 14.26      , 19.4       ,\n",
       "       13.8       , 27.775     , 50.        , 18.54      , 20.92      ,\n",
       "       13.675     , 42.5       , 50.        , 42.5       , 20.51666667,\n",
       "       19.36666667, 13.71428571, 21.11666667, 17.4875    , 14.42      ,\n",
       "       21.54      , 11.72      , 22.44      , 24.86      , 19.7       ,\n",
       "       24.86      , 23.72857143, 42.5       , 18.6       , 10.08333333,\n",
       "       12.425     , 22.73333333, 24.42      , 42.5       , 13.74      ,\n",
       "       20.92      , 23.72857143, 31.13333333, 19.2       , 27.91428571,\n",
       "       10.08333333, 27.91428571, 22.73333333, 36.31428571, 11.55      ,\n",
       "       17.03333333, 12.425     , 14.42      , 27.64      , 17.33333333,\n",
       "       45.74      , 21.24285714, 36.8       , 19.7       , 22.44      ,\n",
       "       17.33333333, 20.51666667, 36.31428571, 21.03333333, 26.24      ,\n",
       "       18.6       , 13.8       , 17.03333333, 18.6       , 21.03333333,\n",
       "       20.14      , 19.7       , 18.54      , 17.33333333, 45.74      ,\n",
       "       20.9       , 13.71428571, 15.6       , 19.7       , 36.8       ,\n",
       "       36.31428571, 17.33333333, 12.425     , 21.08888889, 11.72      ,\n",
       "       27.52857143, 25.3625    , 20.51666667, 35.6       , 19.7       ,\n",
       "       27.91428571, 21.08888889, 20.68571429, 21.08888889, 27.775     ,\n",
       "       25.48      , 23.72857143, 26.24      , 21.24285714, 35.6       ,\n",
       "       18.35714286, 27.91428571, 42.5       , 18.54      , 13.675     ,\n",
       "       17.4875    , 19.2       , 11.55      , 14.4       , 19.7       ,\n",
       "       25.3625    , 25.48      , 19.2       , 21.08888889, 13.71428571,\n",
       "       15.6       , 17.33333333, 20.51666667, 20.14      , 27.52857143,\n",
       "       19.7       , 14.42      , 12.425     , 32.95      , 13.675     ,\n",
       "       20.9       , 21.24285714, 42.5       , 28.37142857, 21.54      ,\n",
       "       10.08333333, 21.54      , 13.8       , 13.8       , 13.675     ,\n",
       "       18.6       , 20.47142857, 35.28      , 27.52857143, 19.2       ,\n",
       "       19.51428571, 19.2       ,  8.43333333, 22.28333333, 36.31428571,\n",
       "       23.72857143, 42.5       , 13.8       , 20.68571429, 12.425     ,\n",
       "       21.03333333, 19.7       , 25.48      , 20.14      , 19.7       ,\n",
       "       27.64      , 19.7       , 24.86      , 17.4875    , 19.2       ,\n",
       "       20.92      , 27.64      , 35.28      , 35.28      , 13.71428571,\n",
       "       23.66      , 27.64      , 21.11666667, 24.42      , 10.08333333,\n",
       "       42.5       , 14.82      , 11.55      , 21.03333333, 14.4       ,\n",
       "       22.44      , 45.74      , 28.37142857, 20.47142857, 13.74      ,\n",
       "       27.52857143, 28.37142857, 13.82857143, 45.74      , 21.08888889,\n",
       "       20.68571429, 20.47142857, 20.9       , 45.74      , 23.04      ,\n",
       "       13.71428571, 13.82857143, 18.6       , 45.74      , 15.6       ,\n",
       "       22.44      , 11.72      , 23.66      , 21.11666667, 28.37142857,\n",
       "       20.14      , 31.13333333, 14.4       , 20.14      , 34.54      ,\n",
       "       13.8       , 32.95      , 18.35714286, 19.2       , 14.42      ,\n",
       "       24.86      , 19.4       , 20.9       , 45.74      , 17.33333333,\n",
       "       14.42      , 28.38      , 19.525     , 17.03333333, 18.35714286,\n",
       "       14.38      , 50.        , 27.775     , 50.        , 20.47142857,\n",
       "       20.47142857, 25.3625    , 21.24285714, 35.6       , 10.08333333,\n",
       "       25.3625    , 27.91428571, 36.8       , 32.95      , 24.86      ,\n",
       "       21.03333333, 10.08333333, 21.24285714, 19.51428571, 13.82857143,\n",
       "       36.31428571, 19.7       , 45.74      , 20.14      , 31.13333333,\n",
       "       20.14      , 21.24285714, 17.4875    , 23.66      , 22.28333333,\n",
       "        8.43333333, 18.54      , 31.13333333, 20.14      , 17.33333333,\n",
       "       27.91428571, 12.425     , 12.425     , 42.5       , 23.72857143,\n",
       "       18.6       , 20.51666667, 19.525     , 27.52857143, 24.86      ,\n",
       "       19.525     , 18.54      , 28.37142857, 24.42      , 14.38      ,\n",
       "       18.54      , 23.66      , 19.36666667, 23.94      , 24.42      ,\n",
       "       50.        ,  8.43333333, 25.3625    , 14.38      , 15.6       ,\n",
       "       17.4875    , 22.73333333, 23.94      , 18.6       , 20.9       ,\n",
       "       13.675     , 25.3625    , 21.11666667, 27.91428571, 27.91428571,\n",
       "        8.64      , 14.4       , 17.03333333, 11.55      , 21.24285714,\n",
       "       23.04      , 18.6       , 11.72      , 19.51428571, 42.5       ,\n",
       "       20.47142857, 20.92      , 21.03333333, 31.13333333, 22.44      ,\n",
       "       14.26      , 10.08333333, 12.425     , 17.4875    , 32.95      ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "unexpected-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.4, 14.4, 23.1, 12. , 21. , 24.5, 14.9, 11.8, 28.2, 31. , 18. ,\n",
       "        8.3, 24.5, 29. , 23.5, 43.8, 20. ,  7.5, 23. , 22.5, 16.8, 15. ,\n",
       "       48.5, 16.6,  7. , 24.1, 33.8, 41.7, 27. , 15.6, 18.2, 16.5, 23.4,\n",
       "       24.1, 21.4, 22.9, 23.3, 37.2, 16.7, 22.8, 25. , 29.8, 17. , 19.2,\n",
       "       13.4, 17.2, 18.8, 14.1, 13.5, 21.4, 21.7, 11.9, 24.8, 20.6, 20.4,\n",
       "       32. , 22. , 36. , 23.1,  8.4, 21.9, 22.6, 28.6, 24. , 12.6, 24.3,\n",
       "       33.3, 20.7, 27.5, 23.7, 31.5, 24.8, 28.7, 20.8,  8.8, 33. , 22.2,\n",
       "       26.7, 19.3, 10.5, 14.9, 18.9, 20.6, 20.5, 34.9, 14.4, 24.2, 13.4,\n",
       "       25.3, 48.3, 50. , 29. , 15.4, 39.8, 16.4, 19.1, 17.7, 18.7, 17.2,\n",
       "       23.1, 23. , 17.8, 17.3, 27.1, 23.2, 14.1, 19.4,  7.4, 20.6, 18.3,\n",
       "       44.8, 23.3, 17.5, 13.2, 28.4, 27.9, 35.4, 13.9, 13.3, 20.1, 34.9,\n",
       "       21.5, 35.4,  8.3, 21.2, 43.5, 25. , 25. , 17.2, 18.2, 27.5, 28. ,\n",
       "       50. , 19.8, 22.6, 14.3, 22. , 50. , 43.1, 29.6, 19.4, 13.4, 19.9,\n",
       "       18.5, 17.4, 20.9, 13.6, 23.9, 50. , 21.9, 20.2, 24.4, 23.9, 14.2,\n",
       "       10.2, 12.3, 22.9, 25. , 30.1, 13.5, 24.3, 22.4, 30.5, 20.1, 26.6,\n",
       "        5.6, 28.7, 21.4, 36.1, 10.2, 18.4, 12.1, 14.8, 50. , 16.6, 46.7,\n",
       "       23.8, 27.5, 19.3, 22. , 19.6, 19.4, 33.4, 20.9, 28.1, 20. ,  7.2,\n",
       "       14.5, 13.8, 19.5, 19.4, 19.9, 15. , 18.2, 46. , 22.2, 15.4,  7. ,\n",
       "       19. , 41.3, 26.6, 17.5, 11.5, 20.3, 15.2, 25.1, 30.3, 19.3, 34.9,\n",
       "       16.8, 29.1, 21.2, 22.9, 16.2, 29.9, 22. , 24. , 25. , 15.3, 36.4,\n",
       "       23.2, 29.1, 48.8, 18.3, 15. , 18.5, 17.1, 13.8, 15.2, 19.7, 23.3,\n",
       "       36.2, 18.9, 21.6, 13.8, 15.7, 18.4, 21.7, 23.4, 27.5, 19.1, 15.2,\n",
       "       15.1, 32.4, 10.9, 20.3, 17.4, 31.6, 29.4, 21.7, 11.8, 23.9,  9.6,\n",
       "       10.4, 11.7, 20.1, 20. , 33.2, 23.6, 17.4, 18.5, 17.5,  8.5, 22.4,\n",
       "       36.2, 22.6, 50. , 16.3, 20.4,  9.5, 21. , 20.8, 16.5, 20.3, 16.1,\n",
       "       22.7, 21.4, 23.7, 16. , 18.5, 20.4, 30.7, 44. , 37. , 15.6, 21.9,\n",
       "       36.5, 21.8, 23.1,  9.7, 32.5, 14.6, 10.5, 22. , 17.8, 22. , 50. ,\n",
       "       24.1, 20.6, 13.8, 28.4, 31.5, 13. , 50. , 21.8, 21.7, 19.8, 20.4,\n",
       "       50. , 23.3, 13.1, 14.1, 23.1, 45.4, 17.8, 21.6, 16.2, 20.6, 20.2,\n",
       "       23.7, 22.2, 30.1, 16.7, 19.3, 34.7, 12.7, 32. , 23. , 19.7, 13.9,\n",
       "       23. , 19.4, 20. , 38.7, 21. , 15.6, 31.7, 19.5, 17.1, 21.7, 14.3,\n",
       "       37.6, 24.8, 50. , 21.4, 20.1, 22. , 25. , 33.1,  5. , 24.7, 30.8,\n",
       "       50. , 33.1, 25. , 21.1,  7.2, 21.5, 19.6, 12.7, 37.3, 23.1, 35.2,\n",
       "       18.6, 31.6, 20.5, 22.3, 17.6, 22.8, 20.3, 10.4, 18.8, 31.2, 21.2,\n",
       "       14.5, 25.2, 12.5,  6.3, 22.8, 24.7, 22.7, 21.7, 19.3, 26.5, 50. ,\n",
       "       20. , 18.9, 26.2, 24.6, 13.6, 18.7, 24.7, 19.2, 23.9, 23.7, 50. ,\n",
       "        8.4, 26.4, 14.5, 13.3, 22.5, 24.4, 23.9, 10.2, 19.4, 16.1, 32.2,\n",
       "       24.5, 25. , 20.7,  8.7, 16.1, 17.8, 13.8, 23.8, 23.8, 19.1,  8.1,\n",
       "       19.6, 37.9, 21.2, 19.5, 20.6, 31.1, 24.8, 13.4, 10.9, 13.1, 18.7,\n",
       "       35.1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "homeless-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "relative-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Counter([1,2,2,3,3,3,3])\n",
    "b = Counter([2,2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "protective-aurora",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1, 2: 7, 3: 4})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "surface-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(np.array([2,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "suffering-external",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 3})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "systematic-mercy",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'type' and 'Counter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9ec703c42264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'type' and 'Counter'"
     ]
    }
   ],
   "source": [
    "c+a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "micro-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "a += b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "elementary-freight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1, 2: 7, 3: 4})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "integral-preference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "hired-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 7)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.most_common(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-updating",
   "metadata": {},
   "source": [
    "## Classification Loss Function: gini v.s. entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-group",
   "metadata": {},
   "source": [
    "$$Gini = 1 - \\sum{p^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-henry",
   "metadata": {},
   "source": [
    "$$Entropy=–\\sum{p}⋅log_2{p}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "actual-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gini\n",
    "y = [0,1,1,0,0,0]\n",
    "def gini(y):\n",
    "    \"Return the gini impurity score for values in y\"\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    p = counts / len(y)\n",
    "    return 1 - np.sum( p**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "existing-session",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accepted-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([4, 2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chubby-solid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entropy\n",
    "from scipy.stats import entropy\n",
    "entropy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "successful-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    \"Return the gini impurity score for values in y\"\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    p = counts / len(y)\n",
    "    return - np.sum( p*np.log(p) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "consistent-dietary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6365141682948128"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "chubby-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "def entropy3(labels, base=None):\n",
    "    vc = pd.Series(labels).value_counts(normalize=True, sort=False)\n",
    "    base = math.e if base is None else base\n",
    "    return -(vc * np.log(vc)/np.log(base)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "designing-lighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6365141682948128"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy3(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-praise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
